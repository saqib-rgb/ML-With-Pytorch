{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN24x+bdeRUuxawhiE+ihVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7179663f7f6f4466b35d5bfe243d9c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fc004a6530f4a13b3c1feef1d1e53e4",
              "IPY_MODEL_ebb7e97dced243aba2a4c1f441e485e1",
              "IPY_MODEL_ebba9f72c5624e8ea646c33ff7a61900"
            ],
            "layout": "IPY_MODEL_b9e0aa4fedfd4e419397c276af9b088f"
          }
        },
        "2fc004a6530f4a13b3c1feef1d1e53e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90317c2c8d414879a440d66b5e022c1f",
            "placeholder": "​",
            "style": "IPY_MODEL_5386197db7e243029c08e172021c4c4f",
            "value": "100%"
          }
        },
        "ebb7e97dced243aba2a4c1f441e485e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e18d4184846147db9e36d7233ce8f851",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_384e947f1e7343dfabdb346c85d769e8",
            "value": 5
          }
        },
        "ebba9f72c5624e8ea646c33ff7a61900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca5757e82b847d9b69eb02d94bc5424",
            "placeholder": "​",
            "style": "IPY_MODEL_985631f66f0a41d7a7757f25bddd479f",
            "value": " 5/5 [00:12&lt;00:00,  2.24s/it]"
          }
        },
        "b9e0aa4fedfd4e419397c276af9b088f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90317c2c8d414879a440d66b5e022c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5386197db7e243029c08e172021c4c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e18d4184846147db9e36d7233ce8f851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "384e947f1e7343dfabdb346c85d769e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ca5757e82b847d9b69eb02d94bc5424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "985631f66f0a41d7a7757f25bddd479f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saqib-rgb/ML-With-Pytorch/blob/main/Going_Modular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Let us get some data"
      ],
      "metadata": {
        "id": "dpXk01zDOs7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDydVbSSONOZ",
        "outputId": "5e3b2061-1225-4ea7-a7f2-c7f8d3c77e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory already exists no need to create one\n",
            "Downloading the data from the link right now....\n",
            "unzipping the file downloaded abobe right now....\n",
            "Removing the zipfile from directory right now...\n",
            "Congratulations the zip file has been remove successfully !!\n"
          ]
        }
      ],
      "source": [
        "# we will start by getting the uselful libraries\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# setup path to data folder\n",
        "data_path=Path('data/')\n",
        "image_path=data_path/'pizza_steak_sushi'\n",
        "\n",
        "#let us write some code to soenload some data if it doesnot exist already\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory already exists no need to create one\")\n",
        "else:\n",
        "  print(f'Did not find {image_path} downloading just now....')\n",
        "  image_path.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "# downloading the data with help of context manager \n",
        "with open (data_path/'pizza_steak_sushi.zip','wb') as f:\n",
        "  request=requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n",
        "  print(f'Downloading the data from the link right now....')\n",
        "  f.write(request.content)\n",
        "\n",
        "#Time to unzip the file\n",
        "with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip','r') as zip_ref:\n",
        "  print('unzipping the file downloaded abobe right now....')\n",
        "  zip_ref.extractall(image_path)\n",
        "\n",
        "# as the extraction has been done no need to keep the zip file\n",
        "print(f'Removing the zipfile from directory right now...')\n",
        "os.remove(data_path/\"pizza_steak_sushi.zip\")\n",
        "print('Congratulations the zip file has been remove successfully !!')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let us create folders for training and testin datasets\n",
        "train_dir=image_path/'train'\n",
        "test_dir=image_path/'test'"
      ],
      "metadata": {
        "id": "Ocdppd2_Xg2C"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Creating Datasets and Dataloaders\n",
        "\n",
        "As in the section above we have already got our data and it is in the folder shape required.\n",
        "\n",
        "In this ection we will be forming a dataset from these and than convert them to dataloaders for batch wise training"
      ],
      "metadata": {
        "id": "DXE1zmIgRYHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the required libraries\n",
        "from torchvision import datasets,transforms\n",
        "\n",
        "# let us create a transform so that our data becomes goof enough to be accepted by PyTorch\n",
        "data_transform=transforms.Compose([\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Using ImageFolder to create datasets\n",
        "train_data=datasets.ImageFolder(\n",
        "    root=train_dir,\n",
        "    transform=data_transform\n",
        ")\n",
        "test_data=datasets.ImageFolder(\n",
        "    root=test_dir,\n",
        "    transform=data_transform\n",
        ")\n",
        "\n",
        "print(f'Train data:\\n {train_data}\\n Test data:{test_data}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J1IiI5_S6lh",
        "outputId": "62689c0a-816d-4618-e13b-f7da0032dba6"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data:\n",
            " Dataset ImageFolder\n",
            "    Number of datapoints: 225\n",
            "    Root location: data/pizza_steak_sushi/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               ToTensor()\n",
            "           )\n",
            " Test data:Dataset ImageFolder\n",
            "    Number of datapoints: 75\n",
            "    Root location: data/pizza_steak_sushi/test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us get the class names and class dictionaries\n",
        "class_names=train_data.classes\n",
        "print(class_names)\n",
        "class_dict=train_data.class_to_idx\n",
        "print(class_dict)\n",
        "# we can also check the lenghth our train and test data\n",
        "print(len(train_data),len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVrlPQs5YNx2",
        "outputId": "dfc02eb5-c85e-4467-95d6-abf54a28f717"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pizza', 'steak', 'sushi']\n",
            "{'pizza': 0, 'steak': 1, 'sushi': 2}\n",
            "225 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "# Now let us set the hyperparameters\n",
        "BATCH_SIZE=32\n",
        "NUM_WORKERS=os.cpu_count()\n",
        "# Now it is time to change our datasets to batch form using DataLoaders\n",
        "train_dataloader=DataLoader(dataset=train_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            num_workers=NUM_WORKERS,\n",
        "                            shuffle=True)\n",
        "test_dataloader=DataLoader(dataset=test_data,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           num_workers=NUM_WORKERS,\n",
        "                           shuffle=False)\n",
        "\n",
        "# let us see what has been created\n",
        "train_dataloader,test_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BthFbqAYNn2",
        "outputId": "04355ade-5a09-47dc-cf5d-36fa28ec7ca4"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f1584969490>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f1584969940>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Noe let us see what has been created by checking a single image size\n",
        "img,label=next(iter(train_dataloader))\n",
        "\n",
        "print(f'Image shape:{img.shape}')\n",
        "print(f'label shape:{label.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93gaK6-taBja",
        "outputId": "af03887f-64ce-4984-e60e-c5878aff6f52"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape:torch.Size([32, 3, 64, 64])\n",
            "label shape:torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Making a TinyVGG Model"
      ],
      "metadata": {
        "id": "UHNAzXYRaBf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"\n",
        "  Creates a TinyVGG architecture.\n",
        "\n",
        "  This model replicates the TinyVGG from CNN explainer website\n",
        "\n",
        "  Args:\n",
        "  input_shape: An integer indicating the number of input channels\n",
        "  hidden_units: An integer indicating the number of hidden units\n",
        "  ouput_shape: An integer telling us the number of output channels\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               input_shape:int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int)->None:\n",
        "      super().__init__()\n",
        "      self.conv_block_1=nn.Sequential(\n",
        "          nn.Conv2d(in_channels=input_shape,\n",
        "                    out_channels=hidden_units,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=hidden_units,\n",
        "                    out_channels=hidden_units,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2,\n",
        "                       stride=2)\n",
        "\n",
        "      )\n",
        "      self.conv_block_2=nn.Sequential(\n",
        "          nn.Conv2d(in_channels=hidden_units,\n",
        "                    out_channels=hidden_units,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=hidden_units,\n",
        "                    out_channels=hidden_units,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=3,\n",
        "                       stride=2)\n",
        "          \n",
        "      )\n",
        "      self.Classifier=nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=hidden_units*12*12,\n",
        "                    out_features=output_shape)\n",
        "      )\n",
        "\n",
        "  def forward(self,x:torch.Tensor):\n",
        "    x=self.conv_block_1(x)\n",
        "    # print(x.shape)\n",
        "    x=self.conv_block_2(x)\n",
        "    # print(x.shape)\n",
        "    x=self.Classifier(x)\n",
        "    # print(x.shape)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "h9m9GrvcaBb9"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let us createa device agnostic code\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Now let us create an instance of our first model\n",
        "model_0=TinyVGG(input_shape=3,\n",
        "                hidden_units=10,\n",
        "                output_shape=len(class_names)).to(device)\n",
        "\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C6YTZ3GaBRB",
        "outputId": "58767bdf-fde7-47b6-b3e0-b45a0407bae3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (Classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1440, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now let us set the correct number of hidden units using torchinfo\n"
      ],
      "metadata": {
        "id": "EFJjHP4sg0qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now colab doesnot have torchinfo by default so we have to install it letus doit\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model_0,input_size=[32,3,64,64])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIv_4XJ6hG90",
        "outputId": "0262f347-2942-4fda-c648-840b4a105984"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "TinyVGG                                  [32, 3]                   --\n",
              "├─Sequential: 1-1                        [32, 10, 30, 30]          --\n",
              "│    └─Conv2d: 2-1                       [32, 10, 62, 62]          280\n",
              "│    └─ReLU: 2-2                         [32, 10, 62, 62]          --\n",
              "│    └─Conv2d: 2-3                       [32, 10, 60, 60]          910\n",
              "│    └─ReLU: 2-4                         [32, 10, 60, 60]          --\n",
              "│    └─MaxPool2d: 2-5                    [32, 10, 30, 30]          --\n",
              "├─Sequential: 1-2                        [32, 10, 12, 12]          --\n",
              "│    └─Conv2d: 2-6                       [32, 10, 28, 28]          910\n",
              "│    └─ReLU: 2-7                         [32, 10, 28, 28]          --\n",
              "│    └─Conv2d: 2-8                       [32, 10, 26, 26]          910\n",
              "│    └─ReLU: 2-9                         [32, 10, 26, 26]          --\n",
              "│    └─MaxPool2d: 2-10                   [32, 10, 12, 12]          --\n",
              "├─Sequential: 1-3                        [32, 3]                   --\n",
              "│    └─Flatten: 2-11                     [32, 1440]                --\n",
              "│    └─Linear: 2-12                      [32, 3]                   4,323\n",
              "==========================================================================================\n",
              "Total params: 7,333\n",
              "Trainable params: 7,333\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 181.93\n",
              "==========================================================================================\n",
              "Input size (MB): 1.57\n",
              "Forward/backward pass size (MB): 22.80\n",
              "Params size (MB): 0.03\n",
              "Estimated Total Size (MB): 24.40\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Now it is time for us to do training and testing by creating two functions `train_step()` and `test_step()`"
      ],
      "metadata": {
        "id": "E_IQZhQ_mlKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the librraies required\n",
        "from typing import Tuple\n",
        "def train_step(\n",
        "    model:torch.nn.Module,\n",
        "    dataloader:torch.utils.data.DataLoader,\n",
        "    loss_fn:torch.nn.Module,\n",
        "    optimizer:torch.optim.Optimizer,\n",
        "    device:torch.device)->Tuple[float,float]:\n",
        "    \"\"\"Trains a PyTorch model for single epoch\n",
        "    \n",
        "    Turns a PyTorch model to training mode and then runs through all the \n",
        "    required training steps (forward pass, loss caclulation, optimizer step)\n",
        "\n",
        "    Args:\n",
        "    model : A PyTorch model to be trained\n",
        "    dataloader: Dataloader instance to be trained\n",
        "    loss_fn: A loss function to minimize\n",
        "    optimizer: A Pytorch optimizer to minimize the loss\n",
        "    device: Which target device to compute on\n",
        "\n",
        "    Retruns:\n",
        "    A tuple of training loss and training accuracies\n",
        "    In the form of (train_loss,train_accuracy).\n",
        "\n",
        "    \"\"\"\n",
        "   # let us start by putting thr model in training mode\n",
        "    model.train()\n",
        "    # Set of train loss and train accuracy values\n",
        "    train_loss,train_acc=0,0\n",
        "    # Loop through the batches of dataloader instances\n",
        "    for batch,(X,y) in enumerate(dataloader):\n",
        "      # send all data to traget device\n",
        "      X,y=X.to(device),y.to(device)\n",
        "\n",
        "      # 1. Make a forward pass\n",
        "      y_pred=model(X)\n",
        "\n",
        "      # 2. calculate the loss\n",
        "      loss=loss_fn(y_pred,y)\n",
        "      train_loss+=loss.item()\n",
        "\n",
        "      # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. Loss backward\n",
        "      loss.backward\n",
        "\n",
        "      # 5. optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "      # Calculate and accumulate metric losss\n",
        "      y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
        "      train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n",
        "\n",
        "\n",
        "  # Adjust the train loss and train acc per batch\n",
        "    train_loss=train_loss/len(dataloader)\n",
        "    train_acc=train_acc/len(dataloader)\n",
        "    return train_loss,train_acc\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "5UDGl5gtmlD_"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us build a function for test step\n",
        "def test_step(model:torch.nn.Module,\n",
        "              dataloader:torch.utils.data.DataLoader,\n",
        "              loss_fn:torch.nn.Module,\n",
        "              device:torch.device):\n",
        "  \"\"\"Test a PyTorch model on test data for one epoch\n",
        "\n",
        "  Turns a target PyTorch model to eval mode and then performs\n",
        "  a forward pass on the data \n",
        "\n",
        "  Args:\n",
        "  model: A PyTorch model that is to be trained\n",
        "  dataloader: A DataLoader instance for the model\n",
        "  loss_fn: A PyTorch loss function\n",
        "  device: The devivce to run the target \n",
        "\n",
        "  Returns:\n",
        "   A tuple of testing loss and testing accuracy of the form\n",
        "   (test_loss,test_accuracy)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Let us start by putiing the model to eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # let us initiate test_loss, test_acc\n",
        "  test_loss,test_acc=0,0\n",
        "\n",
        "  #turn on the infernce mode\n",
        "  with torch.inference_mode():\n",
        "    # creating a for loop to go throughthe instance of DataLoader\n",
        "    for batch,(X,y) in enumerate(dataloader):\n",
        "      # sending all data to target device\n",
        "      X,y=X.to(device),y.to(device)\n",
        "\n",
        "      # 1. MAke a forward pass\n",
        "      y_pred=model(X)\n",
        "\n",
        "      # 2. Calculate the loss\n",
        "      loss=loss_fn(y_pred,y)\n",
        "      test_loss+=loss.item()\n",
        "\n",
        "      # Calculate the accuracy\n",
        "      test_pred_labels=y_pred.argmax(dim=1)\n",
        "      test_acc+=(test_pred_labels==y).sum().item()/len(test_pred_labels)\n",
        "\n",
        "  \n",
        "  # adjust the loss and accuracy to loss per batch\n",
        "  test_loss=test_loss/len(dataloader)\n",
        "  test_acc=test_acc/len(dataloader)\n",
        "\n",
        "  return test_loss,test_acc\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oKRp49wqmk69"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now it is time for us to start building out final `train()` function"
      ],
      "metadata": {
        "id": "nHE4_2GCpN6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing thr required libraries\n",
        "from typing import Dict,List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# defininga function\n",
        "def train(model:torch.nn.Module,\n",
        "          train_dataloader:torch.utils.data.DataLoader,\n",
        "          test_dataloader:torch.utils.data.DataLoader,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          loss_fn:torch.nn.Module,\n",
        "          epochs:int,\n",
        "          device:torch.device)-> Dict[str,List[float]]:\n",
        "    \"\"\"Trains a test a PyTorch model for the epochs defined\n",
        "\n",
        "    It passes a PyTorch model through a train and test step functions fora number of epochs\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained and tested\n",
        "    train_dataloader: A DataLoader instance on which model is to be trained\n",
        "    test_dataloader: A DataLoader instance on ehich model is to be tested\n",
        "    optimizer: A Pytorch function to minimize the loss\n",
        "    loss_fn: A PyTorch function to calculate the loss\n",
        "    epochs: Number of times the data is supposed to pass through for training purposes\n",
        "    device: The target device to run the model\n",
        "\n",
        "    Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for \n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "                  train_acc: [...],\n",
        "                  test_loss: [...],\n",
        "                  test_acc: [...]}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Let us create a list of empty dictioaries to store the values of test/train losses and accuracies for each epoch\n",
        "    results={'train_loss':[],\n",
        "             'train_acc':[],\n",
        "             'test_loss':[],\n",
        "             'test_acc':[]}\n",
        "    \n",
        "    # noe let us loop through the training and testing loops for each epoch\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "      train_loss,train_acc=train_step(\n",
        "          model=model,\n",
        "          dataloader=train_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          optimizer=optimizer,\n",
        "          device=device\n",
        "      )\n",
        "      test_loss,test_acc=test_step(\n",
        "          model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device\n",
        "          \n",
        "      )\n",
        "      # let us print out what is happening\n",
        "      print(\n",
        "          f'Epoch:{epoch+1}|'\n",
        "          f'train_loss:{train_loss}|'\n",
        "          f\"train_acc:{train_acc}|\"\n",
        "          f'test_loss:{test_loss}|'\n",
        "          f'test_acc{test_acc}'\n",
        "      )\n",
        "      # Time to update the dictionary after every epoch\n",
        "      results['train_loss'].append(train_loss)\n",
        "      results['train_acc'].append(train_acc)\n",
        "      results['test_loss'].append(test_loss)\n",
        "      results['test_acc'].append(test_acc)\n",
        "\n",
        "\n",
        "    return results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U1uC2RvJpNyN"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Function to save the built model\n",
        "\n"
      ],
      "metadata": {
        "id": "NIRzlpr9pNrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing th libraries\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(\n",
        "    model:torch.nn.Module,\n",
        "    target_dir:str,\n",
        "    model_name:str):\n",
        "  \"\"\"Save the PyTorch model to target directory\n",
        "\n",
        "  Args: A PyTorch model to save\n",
        "  target_dir: A directory for saving the model\n",
        "  model_name: A file name for the saved model should include '.pth'\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a target directory\n",
        "  target_dir_path=Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "  \n",
        "  # create model save path\n",
        "  assert model_name.endswith('.pth') or model_name.endswith('.pt'),'model name should either end in .pth or .pt'\n",
        "  model_save_path=target_dir_path/model_name\n",
        "\n",
        "  # save the model state_dict()\n",
        "  print(f'[INFO] saving model path to:{model_save_path}')\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)\n"
      ],
      "metadata": {
        "id": "hYt7UbLbupEs"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train evaluate and save the model\n",
        "NUM_EPOCHS=5\n",
        "\n",
        "# Recreating an instance of TinyVGG\n",
        "model_0=TinyVGG(input_shape=3,\n",
        "                hidden_units=10,\n",
        "                output_shape=len(train_data.classes)).to(device)\n",
        "\n",
        "# Setting up loss function and optimizer\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(params=model_0.parameters(),\n",
        "                           lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time=timer()\n",
        "\n",
        "# Train model_0\n",
        "model_0_results=train(\n",
        "    model=model_0,\n",
        "    train_dataloader=train_dataloader,\n",
        "    test_dataloader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "end_time=timer()\n",
        "print(f'The model took {start_time-end_time} to train')\n",
        "\n",
        "# save the model\n",
        "save_model(model=model_0,\n",
        "           target_dir='models',\n",
        "           model_name='going_modular.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "7179663f7f6f4466b35d5bfe243d9c57",
            "2fc004a6530f4a13b3c1feef1d1e53e4",
            "ebb7e97dced243aba2a4c1f441e485e1",
            "ebba9f72c5624e8ea646c33ff7a61900",
            "b9e0aa4fedfd4e419397c276af9b088f",
            "90317c2c8d414879a440d66b5e022c1f",
            "5386197db7e243029c08e172021c4c4f",
            "e18d4184846147db9e36d7233ce8f851",
            "384e947f1e7343dfabdb346c85d769e8",
            "3ca5757e82b847d9b69eb02d94bc5424",
            "985631f66f0a41d7a7757f25bddd479f"
          ]
        },
        "id": "moWU9cw2wraR",
        "outputId": "0ae757a2-6cf9-4c64-f871-69b8cbef531f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7179663f7f6f4466b35d5bfe243d9c57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1|train_loss:1.0933694243431091|train_acc:0.40234375|test_loss:1.0798007249832153|test_acc0.5416666666666666\n",
            "Epoch:2|train_loss:1.1051973104476929|train_acc:0.28125|test_loss:1.0798007249832153|test_acc0.5416666666666666\n",
            "Epoch:3|train_loss:1.0934048295021057|train_acc:0.40234375|test_loss:1.0798007249832153|test_acc0.5416666666666666\n",
            "Epoch:4|train_loss:1.0934325605630875|train_acc:0.40234375|test_loss:1.0798007249832153|test_acc0.5416666666666666\n",
            "Epoch:5|train_loss:1.0926230996847153|train_acc:0.40234375|test_loss:1.0798007249832153|test_acc0.5416666666666666\n",
            "The model took -12.005202604999795 to train\n",
            "[INFO] saving model path to:models/going_modular.pth\n"
          ]
        }
      ]
    }
  ]
}